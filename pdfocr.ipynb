{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10612591,"sourceType":"datasetVersion","datasetId":6570177}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T19:55:38.738630Z","iopub.execute_input":"2025-01-29T19:55:38.739039Z","iopub.status.idle":"2025-01-29T19:55:38.744931Z","shell.execute_reply.started":"2025-01-29T19:55:38.739006Z","shell.execute_reply":"2025-01-29T19:55:38.743377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pytesseract PyMuPDF opencv-python python-Levenshtein","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T19:55:53.141237Z","iopub.execute_input":"2025-01-29T19:55:53.141592Z","iopub.status.idle":"2025-01-29T19:56:04.353098Z","shell.execute_reply.started":"2025-01-29T19:55:53.141563Z","shell.execute_reply":"2025-01-29T19:56:04.351716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport time\nimport random\nimport os\n\ndef safe_pdf_downloader(urls, save_dir=\"downloaded_pdfs\", delay_range=(5, 15), proxies=None):\n    \"\"\"\n    Safely download multiple PDFs with anti-ban measures\n    \n    Args:\n        urls (list): List of PDF URLs to download\n        save_dir (str): Directory to save PDFs (default: 'downloaded_pdfs')\n        delay_range (tuple): Min/max delay between requests in seconds (default: 5-15)\n        proxies (dict): Optional proxies for request rotation\n    \"\"\"\n    # Common desktop User-Agents (expand this list)\n    user_agents = [\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.3\",\n        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 14_3_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.1\",\n        \"Mozilla/5.0 (Windows NT 10.0; rv:122.0) Gecko/20100101 Firefox/122.0\",\n        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.3\"\n    ]\n\n    # Create save directory if not exists\n    os.makedirs(save_dir, exist_ok=True)\n\n    for i, url in enumerate(urls):\n        try:\n            # Generate random delay (except first request)\n            if i > 0:\n                delay = random.uniform(*delay_range)\n                print(f\"Waiting {delay:.1f} seconds before next request...\")\n                time.sleep(delay)\n\n            # Get filename from URL\n            filename = url.split(\"/\")[-1]\n            save_path = os.path.join(save_dir, filename)\n\n            # Skip existing files\n            if os.path.exists(save_path):\n                print(f\"Skipping existing file: {filename}\")\n                continue\n\n            # Rotate headers and proxies\n            headers = {\n                \"User-Agent\": random.choice(user_agents),\n                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n                \"Accept-Language\": \"en-US,en;q=0.5\",\n            }\n\n            print(f\"Downloading ({i+1}/{len(urls)}): {filename}\")\n            \n            # Stream download with timeout\n            response = requests.get(\n                url,\n                headers=headers,\n                proxies=proxies,\n                stream=True,\n                timeout=20\n            )\n            \n            # Check for 4xx/5xx errors\n            response.raise_for_status()\n\n            # Save content\n            with open(save_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:  # filter out keep-alive chunks\n                        f.write(chunk)\n\n            print(f\"Successfully saved: {save_path}\")\n\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 429:\n                print(\"Rate limited - consider increasing delays or using proxies\")\n                return  # Abort on rate limit\n            print(f\"HTTP Error {e.response.status_code} for {url}\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {url}: {str(e)}\")\n        except Exception as e:\n            print(f\"Unexpected error: {str(e)}\")\n\nif __name__ == \"__main__\":\n    # Example usage\n    pdf_urls = [\n        \"https://www.resmigazete.gov.tr/eskiler/2025/01/20250121-27.pdf\",\n        # Add more URLs here\n    ]\n\n    safe_pdf_downloader(\n        pdf_urls,\n        save_dir=\"resmi_gazete_pdfs\",\n        delay_range=(10, 30),  # More conservative delays\n        # proxies={\"http\": \"http://10.10.1.10:3128\"}  # Uncomment to use proxies\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:08:04.410176Z","iopub.execute_input":"2025-01-29T20:08:04.410575Z","iopub.status.idle":"2025-01-29T20:08:24.449218Z","shell.execute_reply.started":"2025-01-29T20:08:04.410543Z","shell.execute_reply":"2025-01-29T20:08:24.448075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:34:55.991753Z","iopub.execute_input":"2025-01-29T20:34:55.992207Z","iopub.status.idle":"2025-01-29T20:39:44.263641Z","shell.execute_reply.started":"2025-01-29T20:34:55.992173Z","shell.execute_reply":"2025-01-29T20:39:44.262043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget -P /usr/share/tesseract-ocr/4.00/tessdata/ https://github.com/tesseract-ocr/tessdata_best/raw/main/tur.traineddata\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:03:01.746064Z","iopub.execute_input":"2025-01-29T20:03:01.746458Z","iopub.status.idle":"2025-01-29T20:03:03.056561Z","shell.execute_reply.started":"2025-01-29T20:03:01.746429Z","shell.execute_reply":"2025-01-29T20:03:03.055208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import fitz  # PyMuPDF\nimport cv2\nimport numpy as np\nimport pytesseract\nfrom pytesseract import Output\nimport re\n\n# 1. INSTALL FIRST\n# - Tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n# - Turkish language data: `tur.traineddata` in Tesseract's tessdata folder\n# - Install packages: pip install pytesseract PyMuPDF opencv-python\n\ndef pdf_to_images(pdf_path):\n    \"\"\"Convert PDF pages to images\"\"\"\n    doc = fitz.open(pdf_path)\n    images = []\n    \n    for page in doc:\n        pix = page.get_pixmap(dpi=300)  # High DPI for better OCR\n        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape((pix.height, pix.width, 3))\n        images.append(img)\n    \n    return images\n\ndef preprocess_image(img):\n    \"\"\"Enhance image for better OCR results\"\"\"\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    denoised = cv2.fastNlMeansDenoising(gray, h=30)\n    scaled = cv2.resize(denoised, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n    _, threshold = cv2.threshold(scaled, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    return threshold\n\ndef ocr_turkish(image):\n    \"\"\"Perform OCR on preprocessed image with Turkish language\"\"\"\n    custom_config = r'--oem 3 --psm 6 -l tur'\n    details = pytesseract.image_to_data(image, output_type=Output.DICT, config=custom_config)\n    return details\n\ndef parse_legal_document(text):\n    \"\"\"Parse Turkish legal text structure\"\"\"\n    # Example patterns for Resmi Gazete\n    patterns = {\n        'date': r'\\d{2}\\.\\d{2}\\.\\d{4}',\n        'law_number': r'(?:Kanun|Yönetmelik)\\s+N[oö]\\.?\\s*[\\d-]+',\n        'section': r'(?:Madde|MADDE)\\s+\\d+',\n        'paragraph': r'\\(\\d+\\)'\n    }\n    \n    results = {}\n    for key, pattern in patterns.items():\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        if matches:\n            results[key] = matches\n            \n    return results\n\ndef process_scanned_pdf(pdf_path):\n    images = pdf_to_images(pdf_path)\n    all_text = []\n    \n    for idx, img in enumerate(images):\n        print(f\"Processing page {idx+1}/{len(images)}\")\n        processed = preprocess_image(img)\n        ocr_result = ocr_turkish(processed)\n        \n        # Combine text lines\n        page_text = ' '.join([word for word in ocr_result['text'] if word.strip()])\n        parsed = parse_legal_document(page_text)\n        \n        all_text.append({\n            'page': idx+1,\n            'raw_text': page_text,\n            'parsed': parsed\n        })\n    \n    return all_text\n\n# Usage\nresult = process_scanned_pdf(\"/kaggle/input/yargtay/20250121-27.pdf\")\n\n# Print sample results\nfor page in result:\n    print(f\"\\nPage {page['page']}:\")\n    print(\"Found sections:\", page['parsed'].get('section', []))\n    print(\"Found dates:\", page['parsed'].get('date', []))\n    print(\"Sample text:\", page['raw_text'][:500] + \"...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:03:11.713661Z","iopub.execute_input":"2025-01-29T20:03:11.714151Z","iopub.status.idle":"2025-01-29T20:04:06.743157Z","shell.execute_reply.started":"2025-01-29T20:03:11.714113Z","shell.execute_reply":"2025-01-29T20:04:06.741942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt install tesseract-ocr\n!sudo apt install libtesseract-dev\n!wget https://github.com/tesseract-ocr/tessdata/raw/main/tur.traineddata\n!mkdir -p /usr/share/tesseract-ocr/4.00/tessdata/\n!mv tur.traineddata /usr/share/tesseract-ocr/4.00/tessdata/\n\nimport fitz\nimport cv2\nimport numpy as np\nimport pytesseract\nfrom pytesseract import Output\nimport re\nimport os\n\n# Set Tesseract path explicitly for Kaggle\npytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\nos.environ['TESSDATA_PREFIX'] = '/usr/share/tesseract-ocr/4.00/tessdata/'\n\ndef pdf_to_images(pdf_path):\n    \"\"\"Convert PDF pages to images\"\"\"\n    doc = fitz.open(pdf_path)\n    images = []\n    \n    for page in doc:\n        pix = page.get_pixmap(dpi=300)\n        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape((pix.height, pix.width, 3))\n        images.append(img)\n    \n    return images\n\ndef preprocess_image(img):\n    \"\"\"Enhanced preprocessing for Kaggle environment\"\"\"\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    # Improved denoising\n    denoised = cv2.fastNlMeansDenoising(\n        gray,\n        h=30,\n        templateWindowSize=7,\n        searchWindowSize=21\n    )\n    \n    # Contrast Limited Adaptive Histogram Equalization\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    enhanced = clahe.apply(denoised)\n    \n    # Sharpening\n    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n    sharpened = cv2.filter2D(enhanced, -1, kernel)\n    \n    return sharpened\n\ndef ocr_turkish(image):\n    \"\"\"Kaggle-optimized Turkish OCR\"\"\"\n    custom_config = r'--oem 3 --psm 6 -l tur --tessdata-dir /usr/share/tesseract-ocr/4.00/tessdata/'\n    try:\n        return pytesseract.image_to_data(image, output_type=Output.DICT, config=custom_config)\n    except Exception as e:\n        print(f\"OCR Error: {str(e)}\")\n        return {'text': []}\n\n# Rest of your existing functions remain the same...\n\n# Usage\nresult = process_scanned_pdf(\"/kaggle/input/yargtay/20250121-27.pdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:09:35.543654Z","iopub.execute_input":"2025-01-29T20:09:35.544080Z","iopub.status.idle":"2025-01-29T20:10:30.416939Z","shell.execute_reply.started":"2025-01-29T20:09:35.544048Z","shell.execute_reply":"2025-01-29T20:10:30.415104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:12:08.139653Z","iopub.execute_input":"2025-01-29T20:12:08.140129Z","iopub.status.idle":"2025-01-29T20:12:08.152670Z","shell.execute_reply.started":"2025-01-29T20:12:08.140091Z","shell.execute_reply":"2025-01-29T20:12:08.151341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_ocr_results(result, output_dir=\"ocr_results\"):\n    # Create output directory\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for page_data in result:\n        filename = f\"page_{page_data['page']}.txt\"\n        filepath = os.path.join(output_dir, filename)\n        \n        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n            f.write(f\"=== Page {page_data['page']} ===\\n\")\n            f.write(\"RAW TEXT:\\n\")\n            f.write(page_data['raw_text'] + \"\\n\\n\")\n            f.write(\"STRUCTURED DATA:\\n\")\n            for key, values in page_data['parsed'].items():\n                f.write(f\"{key.upper()}: {', '.join(values)}\\n\")\n                \n        print(f\"Saved: {filepath}\")\n\n# Usage\nsave_ocr_results(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:13:29.803511Z","iopub.execute_input":"2025-01-29T20:13:29.803931Z","iopub.status.idle":"2025-01-29T20:13:29.814522Z","shell.execute_reply.started":"2025-01-29T20:13:29.803896Z","shell.execute_reply":"2025-01-29T20:13:29.813385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install FPDF","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:14:43.255511Z","iopub.execute_input":"2025-01-29T20:14:43.255901Z","iopub.status.idle":"2025-01-29T20:14:50.119621Z","shell.execute_reply.started":"2025-01-29T20:14:43.255861Z","shell.execute_reply":"2025-01-29T20:14:50.118180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fpdf import FPDF\n\ndef create_searchable_pdf(result, output_path=\"searchable.pdf\"):\n    # Initialize PDF with UTF-8 support\n    pdf = FPDF()\n    pdf.set_auto_page_break(auto=True, margin=15)\n    \n    # Add Unicode-compatible font (make sure this font supports Turkish characters)\n    pdf.add_font(\"DejaVu\", \"\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", uni=True)\n    pdf.set_font(\"DejaVu\", size=12)\n    \n    for page_data in result:\n        pdf.add_page()\n        # Page number header\n        pdf.cell(0, 10, f\"Sayfa {page_data['page']}\", ln=1)\n        # Add UTF-8 encoded text\n        try:\n            pdf.multi_cell(0, 10, txt=page_data['raw_text'])\n        except UnicodeEncodeError:\n            # Fallback for problematic characters\n            cleaned_text = page_data['raw_text'].encode('latin-1', 'replace').decode('latin-1')\n            pdf.multi_cell(0, 10, txt=cleaned_text)\n    \n    pdf.output(output_path)\n    print(f\"Oluşturulan PDF: {output_path}\")\n\n# First install required fonts in Kaggle:\n!apt-get update -qq && apt-get install -y fonts-dejavu\n\n# Then run\ncreate_searchable_pdf(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:17:22.994105Z","iopub.execute_input":"2025-01-29T20:17:22.994491Z","iopub.status.idle":"2025-01-29T20:17:36.165281Z","shell.execute_reply.started":"2025-01-29T20:17:22.994463Z","shell.execute_reply":"2025-01-29T20:17:36.163471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Check if file exists\nif os.path.exists(\"searchable.pdf\"):\n    print(\"File exists. Size:\", os.path.getsize(\"searchable.pdf\"), \"bytes\")\nelse:\n    print(\"File not created!\")\n\n# List all files in directory\nprint(\"\\nFiles in current folder:\")\nprint(os.listdir(\".\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:19:43.528126Z","iopub.execute_input":"2025-01-29T20:19:43.528572Z","iopub.status.idle":"2025-01-29T20:19:43.537119Z","shell.execute_reply.started":"2025-01-29T20:19:43.528535Z","shell.execute_reply":"2025-01-29T20:19:43.535841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Force file download\nFileLink(\"searchable.pdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T20:20:23.611653Z","iopub.execute_input":"2025-01-29T20:20:23.612071Z","iopub.status.idle":"2025-01-29T20:20:23.619318Z","shell.execute_reply.started":"2025-01-29T20:20:23.612038Z","shell.execute_reply":"2025-01-29T20:20:23.618285Z"}},"outputs":[],"execution_count":null}]}